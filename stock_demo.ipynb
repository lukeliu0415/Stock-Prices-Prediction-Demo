{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Stock Market Prices Using Linear & Polynomial Regression\n",
    "\n",
    "__Author:__ Luke Liu,   __Course:__ EECS 16A,   __Term:__ Fall 2019\n",
    "\n",
    "## Introduction\n",
    "The stock market is an extremely complex system that is difficult to model due to a large number of factors that determine the day-to-day price changes. One of the most exciting and useful applications of machine learning, is to predict these price changes days, months, or perhaps years into the future. Although this application was briefly mentioned by Professor Ranade in lecture, it is unfortunately not further explored in the context of EECS 16A. In this demo, we will build our own linear regression and polynomial regression models based on historical stock prices from top companies, examine their effectiveness, and use them to predict price changes in the stock market. In the end, we will also explore higher-level machine learning techniques that can be used more effectively to achieve our goal.\n",
    "\n",
    "<img src=\"img/stock.jpg\" align=\"center\" style=\"height:200px\">\n",
    "\n",
    "Wait... What even is linear regression and polynomial regression??\n",
    "\n",
    "### Linear Regression\n",
    "Linear regression models the relationship between two variables through fitting a linear line of best fit to the observed data. It is the most basic and one of the most widely used predictive analysis techniques in machine learning. The general linear regression formula is:\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = {\\alpha}_0 + {\\alpha}_1 x_i + {\\epsilon}_i\n",
    "\\end{equation}\n",
    "\n",
    "To revisit, Homework 13 Question 2 is an example of building a linear regression model: http://www.eecs16a.org/homework/prob13.pdf\n",
    "\n",
    "### Polynomial Regression\n",
    "Polynomial regression is a special case of linear regression. It models the relationship between two variables through fitting an n-th degree polynomial to the observed data. The general polynomial regression formula is:\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = {\\alpha}_0 + {\\alpha}_1 x_i  + {\\alpha}_2 x_i^2 + ... + {\\alpha}_n x_i^n + {\\epsilon}_i\n",
    "\\end{equation}\n",
    "\n",
    "To revisit, Discussion 13A Question 3 is an example of building a polynomial regression model of degree 4: http://www.eecs16a.org/discussion/dis13A.pdf#page=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Code\n",
    "\n",
    "You do not have to worry about understanding the code here. Source: Homework 14 Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"Function that constructs a polynomial curve for a set of coefficients\n",
    "   that multiply the polynomial terms and the x range.\"\"\"\n",
    "def poly_curve(params,x_input):\n",
    "    # params contains the coefficients that multiply the polynomial terms, in degree of lowest degree to highest degree\n",
    "    degree=len(params)-1\n",
    "    x_range=[x_input[1], x_input[-1]]\n",
    "    x=np.linspace(x_range[0],x_range[1],1000)\n",
    "    y=x*0\n",
    "    \n",
    "    for k in range(0,degree+1):\n",
    "        coeff=params[k]\n",
    "        y=y+list(map(lambda z:coeff*z**k,x))        \n",
    "    return x,y\n",
    "    \n",
    "\"\"\"Function that defines a data matrix for some input data.\"\"\"\n",
    "def data_matrix(input_data,degree):\n",
    "    # degree is the degree of the polynomial you plan to fit the data with    \n",
    "    Data=np.zeros((len(input_data),degree+1))\n",
    "    \n",
    "    for k in range(0,degree+1):\n",
    "        Data[:,k]=(list(map(lambda x:x**k ,input_data)))\n",
    "                  \n",
    "    return Data\n",
    "\n",
    "\"\"\"Given a set of x and y points, and a range of polynomial degrees to try, this function calculates polynomial \n",
    "   fits to the data for polynomials of different degrees. It returns the \"cost\", i.e. the magnitude of the error\n",
    "   vector for each fit. The output is an array of the cost corresponding to each degree. \"\"\"\n",
    "def cost(x, y, start_deg, end_deg):\n",
    "    c = []\n",
    "    for degree in range(start_deg, end_deg):\n",
    "        D = data_matrix(x, degree)\n",
    "        params = leastSquares(D, y)\n",
    "        error = np.linalg.norm(y-np.dot(D, params))\n",
    "        c.append(error)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Import Real Data!\n",
    "\n",
    "Historical stock data for top tech companies (Facebook, Apple, Amazon) have already been compiled from Yahoo Finance. It consists of all their stock prices from the last year __(Dec. 10, 2018 to Dec. 5, 2019)__. Fun (and important) fact: Stock market only runs on __business days__! As a result, there would only be a total of 250 days in the data. Feel free to check out their CSV spreadsheets contained in the demo folder; their data contain each day's opening, highest, lowest, closing prices, and more. However, we will only use the __closing price of stocks__ at the end of each business day. Although day trading is not modeled, it is an active area of research that you are encouraged to look into!\n",
    "\n",
    "Now it's time to pick your favourite company!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = np.loadtxt('data/apple.csv', delimiter=\",\", skiprows=1, usecols=(1, 4))\n",
    "facebook = np.loadtxt('data/facebook.csv', delimiter=\",\", skiprows=1, usecols=(1, 4))\n",
    "amazon = np.loadtxt('data/amazon.csv', delimiter=\",\", skiprows=1, usecols=(1, 4))\n",
    "\n",
    "stock_data = apple ### Your choice here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real-world machine learning, the observed data is typically divided into the following three sets. In the simplest words,\n",
    "\n",
    "__Training Set:__ This set is used to fit the model.\n",
    "\n",
    "__Validation Set:__ This set evaluates the effectiveness of the model and adjusts it when necessary.\n",
    "\n",
    "__Testing Set:__ This set evaluates the effectiveness of the final model.\n",
    "\n",
    "<img src=\"img/division.png\" align=\"center\" style=\"height:150px\">\n",
    "<center> A visualization of the split </center>\n",
    "\n",
    "__Credit/I recommend further reading here:__ https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity purposes, we will only be dealing with training set and testing set. Validation set is beyond the scope of EECS 16A.\n",
    "\n",
    "We will be dedicating 80% of the data (200 days) towards the training set and 20% of the data (50 days) towards the testing set. Since we do do not know whether our model would accurately fit the testing data, it is safer that the testing set contains days that come before the days in the training set, so we can more effectively predict future prices.\n",
    "\n",
    "Our testing set contains the stock market prices from day 1 to 50, while the training set contains the stock market prices from day 51 to 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_change = 51\n",
    "training_data = stock_data[day_change:]\n",
    "testing_data = stock_data[:day_change]\n",
    "\n",
    "dates, prices = stock_data[:, 0], stock_data[:, 1]\n",
    "dates_t, prices_t = training_data[:, 0], training_data[:, 1]\n",
    "dates_v, prices_v = testing_data[:, 0], testing_data[:, 1]\n",
    "dates_p = np.arange(1, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the block below to see the company's stock trend last year. Keep in mind we will use the days 51-250 to fit the data and days 1-50 to see how effective the fit is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(dates, prices)\n",
    "plt.title('Stock Price', fontsize=16)\n",
    "plt.axvline(day_change, color='gray', linestyle='--')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "### Stage 1: Training/Modeling\n",
    "\n",
    "First, we will apply the linear regression technique to model the stock price. Recall the equation\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = {\\alpha}_0 + {\\alpha}_1 x_i\n",
    "\\end{equation}\n",
    "\n",
    "<span style='color:red'><b> What are the unknowns in this case? What is given? What technique can we use to solve this system?</b> </span>\n",
    "\n",
    "__Answer:__ The unknowns are $\\alpha_0$ and $\\alpha_1$. There are 250 sets of $x_i$ (date) and $y_i$ (stock price) that are given (there are 250 days!) When there are more equations than variables (aka. when a system is overdetermined), we use least squares and model the problem as following:\n",
    "\n",
    "$$ \\large\n",
    "\\begin{bmatrix}\n",
    "    1 & \n",
    "        x_1 \\\\\n",
    "    1 & \n",
    "        x_2 \\\\\n",
    "    \\vdots & \n",
    "        \\vdots  \\\\\n",
    "    1 & \n",
    "        x_{250} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "    \\alpha_0 \\\\  \n",
    "    \\alpha_1 \n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix} \n",
    "    y_0 \\\\\n",
    "    y_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    y_{250}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now write the function that computes the least squares solution and solve for $\\vec{\\alpha}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function that computes the Least Squares Approximation\"\"\"\n",
    "def leastSquares(A, y):\n",
    "    return np.dot(np.linalg.inv(np.dot(A.T, A)), np.dot(A.T, y)) ### Your answer here\n",
    "\n",
    "D_a = data_matrix(dates_t, 1) # Turn the dates into the matrix form\n",
    "sol_a = leastSquares(D_a, prices_t) # Computes least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how you did! Run the block below to plot your line of best fit as determined through linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "x_line, y_line = poly_curve(sol_a, dates_t)\n",
    "ax.plot(dates_t, prices_t)\n",
    "ax.plot(x_line, y_line, 'r')\n",
    "plt.title('Linear Regression Training: Stock Price', fontsize=16)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Testing\n",
    "\n",
    "In the testing phase, we determine how effective our model is by looking at days 0-50. Run the block below to see the result. Would you say that this is an accurate model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "x_line, y_line = poly_curve(sol_a, dates)\n",
    "ax.plot(dates, prices)\n",
    "ax.plot(x_line, y_line, 'r')\n",
    "plt.axvline(day_change, color='gray', linestyle='--')\n",
    "plt.title('Linear Regression Testing: Stock Price', fontsize=16)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the magnitude of the error vector for the testing set by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = data_matrix(dates_v, 1)\n",
    "error = np.linalg.norm(prices_v-np.dot(D, sol_a))\n",
    "print(\"Magnitude of error vector: \" + str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Predicting\n",
    "\n",
    "Using the linear regression model that you have built, what would be the price of the stock for the company you have chosen in __N__ market days? <br> __(Treat today as December 5, 2019)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5  ### Input your value\n",
    "\n",
    "D = data_matrix([250+N], 1)\n",
    "new_price = np.dot(D, sol_a)[0]\n",
    "print(\"The stock price for the company you have chosen in \" + str(N) + \" market days is: $\" + str(round(new_price, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extend our plot to predict the price for the upcoming 50 days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "x_line, y_line = poly_curve(sol_a, dates_p)\n",
    "ax.plot(dates, prices)\n",
    "ax.plot(x_line, y_line, 'r')\n",
    "plt.axvline(day_change, color='gray', linestyle='--')\n",
    "plt.axvline(250, color='gray', linestyle='--')\n",
    "plt.title('Linear Regression Prediction: Stock Price', fontsize=16)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "<span style='color:red'><b>What can you conclude about the advantages/disadvantages of a linear regression model? Do you think that it is effective?</b> </span>\n",
    "\n",
    "#### Advantages of using Linear Regression:\n",
    "\n",
    "- High level of transparency on how prediction is produced\n",
    "- Universally-accepted and most used/easiest predictive analytics method\n",
    "\n",
    "#### Disadvantages of using Linear Regression:\n",
    "\n",
    "- Can only be used to produce a linear curve\n",
    "- Not that good in predictive analysis as it is highly restricted and and oversimply the complex situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "### Stage 1: Training/Modeling\n",
    "\n",
    "First, we have to determine the degree that we want for the polynomial regression model. With the help of the cost function, we can determine the cost of the error vector for each degree. Intuitively, it may seem like we should pick the degree with the lowest cost because it supposedly fits the data the best. However, the degree with the lowest cost may not represent the best model since it may be due to the presence of outliers - refer to Homework 14 Problem 1 (http://www.eecs16a.org/homework/prob14.pdf). We will tackle this problem by making a decision on which degree to use on our own, by examining the values returned by the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list = cost(dates_t, prices_t, 1, 11)\n",
    "for i in range(10):\n",
    "    print(\"Degree \" + str(i+1) + \": \" + str(cost_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'><b>Which degree would you pick and why?</b></span>\n",
    "\n",
    "__Answer:__ We know that the higher the degree we choose, the more inaccurate our model would become since higher-order polynomials tend to \"overfit.\" It seems like that choosing degree 3 may be the best option since it does not deviate so much from the lowest cost and it is a relatively low-degree polynomial. I encourage you to come back and try different degrees later!\n",
    "\n",
    "Once again, we use least squares to compute the solution to\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = {\\alpha}_0 + {\\alpha}_1 x_i  + {\\alpha}_2 x_i^2 + ... + {\\alpha}_n x_i^n\n",
    "\\end{equation}\n",
    "\n",
    "where n is the degree that we have chosen.\n",
    "\n",
    "$$ \\large\n",
    "\\begin{bmatrix}\n",
    "    1 & \n",
    "        x_1 &\n",
    "            x_1^2 &\n",
    "                \\ldots &\n",
    "                    x_1^n\\\\\n",
    "    1 & \n",
    "        x_2 &\n",
    "            x_2^2 &\n",
    "                \\ldots &\n",
    "                    x_2^n\\\\\n",
    "    \\vdots & \n",
    "        \\vdots &\n",
    "            \\vdots &\n",
    "                \\vdots &\n",
    "                    \\vdots\\\\\n",
    "    1 & \n",
    "        x_{250} &\n",
    "            x_{250}^2 &\n",
    "                \\ldots &\n",
    "                    x_{250}^n\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "    \\alpha_0 \\\\  \n",
    "    \\alpha_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\alpha_n\n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix} \n",
    "    y_0 \\\\\n",
    "    y_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    y_{250}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3 ### Feel free to adjust this value to see different results\n",
    "D_b = data_matrix(dates_t, degree)\n",
    "sol_b = leastSquares(D_b, prices_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how you did! Run the code block below to display your curve of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "x_curve, y_curve = poly_curve(sol_b, dates_t)\n",
    "ax.plot(dates_t, prices_t)\n",
    "ax.plot(x_curve, y_curve, 'r')\n",
    "plt.title('Polynomial Regression Training: Stock Price', fontsize=16)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Testing\n",
    "\n",
    "In the testing phase, we determine how effective our model is by looking at days 0-50. Run the block below to see the result. Would you say that this is an accurate model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "x_curve, y_curve = poly_curve(sol_b, dates)\n",
    "ax.plot(dates, prices)\n",
    "ax.plot(x_curve, y_curve, 'r')\n",
    "plt.axvline(day_change, color='gray', linestyle='--')\n",
    "plt.title('Polynomial Regression Testing: Stock Price', fontsize=16)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the magnitude of the error vector for the testing set by running the code block below. Compare it to the magnitude of error vector you calculated for linear regression. Which one is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = data_matrix(dates_v, degree)\n",
    "error = np.linalg.norm(prices_v-np.dot(D, sol_b))\n",
    "print(\"Magnitude of error vector: \" + str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Predicting\n",
    "\n",
    "Using the polynomial regression you have built, what would be the price of the stock for the company you have chosen in __N__ market days? <br> __(Treat today as December 5, 2019)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5  ### Input your value\n",
    "\n",
    "D = data_matrix([250+N], degree)\n",
    "new_price = np.dot(D, sol_b)[0]\n",
    "print(\"The stock price for the company you have chosen in \" + str(N) + \" market days is: $\" + str(round(new_price, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extend our plot to predict the price for the upcoming 50 days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "x_curve, y_curve = poly_curve(sol_b, dates_p)\n",
    "ax.plot(dates, prices)\n",
    "ax.plot(x_curve, y_curve, 'r')\n",
    "plt.axvline(day_change, color='gray', linestyle='--')\n",
    "plt.axvline(250, color='gray', linestyle='--')\n",
    "plt.title('Polynomial Regression Prediction: Stock Price', fontsize=16)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feel free to go back to stage 1 to test out models of different degrees to see their effectiveness!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "<span style='color:red'><b>What can you conclude about the advantages/disadvantages of a polynomial regression model? Do you think that it is effective?</b></span>\n",
    "\n",
    "#### Advantages of using Polynomial Regression:\n",
    "\n",
    "- Can fit many type of curves\n",
    "- Provide the best approximation of the relationship between the dependent and independent variables\n",
    "\n",
    "#### Disadvantages of using Polynomial Regression:\n",
    "\n",
    "- Too sensitive to outliers (presence of outliers seriously distort the results of a nonlinear analysis)\n",
    "- Tend to diverge very quickly, especially in higher-degree polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As we have seen, linear regression and polynomial regression produced drastically different results towards predicting stock market prices. Although polynomial regression fits the data better and may perform better in the short run, linear regression generally performs better in the long run because it is less likely to overfit the training data. While each has their own advantages and disadvantages, it turns out that neither of these models are good enough to model the price change. Stock market is influenced by many, many factors, including economic growth, interest rates, confidence/expectations, and more.\n",
    "\n",
    "As you embark on the journey of taking EECS 16B and upper division machine learning courses (e.g. CS 189, 182), you will learn more and more effective techniques, and gradually build more robust models towards elusive goals such as predicting the stock market. Hope this demo inspired you and gave you some insight of machine learning in the real world!\n",
    "\n",
    "<img src=\"img/learning.jpg\" align=\"center\" style=\"height:200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Other Machine Learning Techniques\n",
    "\n",
    "What are some other machine learning techniques that can model the stock market price change (effectively or ineffectively)?\n",
    "\n",
    "__NOTE:__ They are out of scope for EECS 16A and are shown below purely for personal interest!\n",
    "\n",
    "### Moving Average: \n",
    "\n",
    "\"Average\" is commonly used in our daily lives, whether for calculating the average marks to determine the overall performance in a course or finding the average temperature in the past few days to get an idea of today's temperature. This method, even simpler than linear regression, is a great starting point for making predictions.\n",
    "\n",
    "In the stock market model, the predicted closing price would just be the average of previously observed values. The \"moving\" average would use the latest set of values for prediction; for each subsequent step, the predicted values are taken into consideration while removing the oldest observed value from the set.\n",
    "\n",
    "<img src=\"img/average.png\" align=\"center\" style=\"height:200px\">\n",
    "\n",
    "### k-Nearest Neighbours\n",
    "\n",
    "Based on independent variables, kNN finds the similarity between new data points and old data points. In the below example, there are sets of age and height for 10 people. To determine the weight for #11, we consider the weight of the nearest neighbours of this ID; the weight of #11 is predicted to be the average of its three nearest neighbours (ID 1, 5, 6): (77+72+60)/3 = 69.66 kg.\n",
    "\n",
    "<img src=\"img/knn.png\" align=\"center\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Prophet Forecasting Model\n",
    "\n",
    "A decomposable time series model with three main model components: trend, seasonality, and holidays. They are combined in the following equation:\n",
    "\n",
    "\\begin{equation}\n",
    "y(t) = g(t) + s(t) + h(t) + {\\epsilon}_t\n",
    "\\end{equation}\n",
    "\n",
    "g(t): piecewise linear or logistic growth curve for modelling non-periodic changes in time series <br>\n",
    "s(t): periodic changes (e.g. weekly/yearly seasonality) <br>\n",
    "h(t): effects of holidays (user provided) with irregular schedules <br>\n",
    "$\\epsilon_t$: error term accounts for any unusual changes not accommodated by the model\n",
    "\n",
    "### Long Term Short Memory (LTSM)\n",
    "\n",
    "A widely used sequence prediction method that is proven to be extremely effective. It is able to store past information that is important, and forget the information that is not. LSTM has three gates:\n",
    "\n",
    "The input gate: The input gate adds information to the cell state <br>\n",
    "The forget gate: It removes the information that is no longer required by the model <br>\n",
    "The output gate: Output Gate at LSTM selects the information to be shown as output\n",
    "\n",
    "__Credit/I recommend further reading here:__ https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/\n",
    "\n",
    "## Credit\n",
    "\n",
    "Special thanks to Ricky Liou, Phoebe Li and Grace Chen for proofreading this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
